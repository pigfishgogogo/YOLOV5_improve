# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""
Loss functions
"""
import numpy as np
import torch
import torch.nn as nn

from utils.metrics import bbox_iou
from utils.torch_utils import de_parallel


def smooth_BCE(eps=0.1):  # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441
    # return positive, negative label smoothing BCE targets
    return 1.0 - 0.5 * eps, 0.5 * eps


class BCEBlurWithLogitsLoss(nn.Module):
    # BCEwithLogitLoss() with reduced missing label effects.
    def __init__(self, alpha=0.05):
        super().__init__()
        self.loss_fcn = nn.BCEWithLogitsLoss(reduction='none')  # must be nn.BCEWithLogitsLoss()
        self.alpha = alpha

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)
        pred = torch.sigmoid(pred)  # prob from logits
        dx = pred - true  # reduce only missing label effects
        # dx = (pred - true).abs()  # reduce missing label and false label effects
        alpha_factor = 1 - torch.exp((dx - 1) / (self.alpha + 1e-4))
        loss *= alpha_factor
        return loss.mean()


class FocalLoss(nn.Module):
    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super().__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = 'none'  # required to apply FL to each element

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)
        # p_t = torch.exp(-loss)
        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability

        # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py
        pred_prob = torch.sigmoid(pred)  # prob from logits
        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = (1.0 - p_t) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss


class QFocalLoss(nn.Module):
    # Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super().__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = 'none'  # required to apply FL to each element

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)

        pred_prob = torch.sigmoid(pred)  # prob from logits
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = torch.abs(true - pred_prob) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss


class ComputeLoss:
    sort_obj_iou = False

    # Compute losses
    def __init__(self, model, autobalance=False):
        device = next(model.parameters()).device  # get model device
        h = model.hyp  # hyperparameters

        # Define criteria
        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))
        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))

        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3
        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets

        # Focal loss
        g = h['fl_gamma']  # focal loss gamma    # g = 0
        if g > 0:  # è¿›ä¸å»
            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)

        m = de_parallel(model).model[-1]  # Detect() module
        self.balance = {3: [4.0, 1.0, 0.4]}.get(m.nl, [4.0, 1.0, 0.25, 0.06, 0.02])  # P3-P7
        self.ssi = list(m.stride).index(16) if autobalance else 0  # stride 16 index
        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance
        self.na = m.na  # number of anchors
        self.nc = m.nc  # number of classes
        self.nl = m.nl  # number of layers
        self.anchors = m.anchors
        self.device = device

    def __call__(self, p, targets):  # predictions, targets
        lcls = torch.zeros(1, device=self.device)  # class loss
        lbox = torch.zeros(1, device=self.device)  # box loss
        lobj = torch.zeros(1, device=self.device)  # object loss
        tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets

        # Losses
        for i, pi in enumerate(p):  # layer index, layer predictions  pæ˜¯æ¨¡å‹é¢„æµ‹è¾“å‡ºç»“æœï¼Œæ˜¯listæœ‰3ä¸ªå…ƒç´ ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯yoloä¸­ä¸€ä¸ªæ£€æµ‹å¤´çš„è¾“å‡ºtensor(16,3,80,80,7)ã€åé¢ä¸¤ä¸ªå…ƒç´ tensorä¸­æ˜¯40ï¼Œ40å’Œ20ï¼Œ20
            b, a, gj, gi = indices[i]  # image, anchor, gridy, gridx  # bæ˜¯targetå±äºå“ªä¸€ä¸ªbatchï¼Œforå¾ªç¯i=0çš„æ—¶å€™aå°±æ˜¯ç¬¬ä¸€å±‚yoloä¸­æ˜ å°„åˆ°ç‰¹å¾å›¾çš„3ä¸ªanchorå°ºå¯¸ï¼Œgjã€giæ˜¯targetåŒ¹é…åˆ°çš„æŸä¸ªanchoræ­£æ ·æœ¬çš„ç½‘æ ¼åæ ‡
            tobj = torch.zeros(pi.shape[:4], dtype=pi.dtype, device=self.device)  # target obj  ï¼ˆ16ï¼Œ3ï¼Œ80ï¼Œ80ï¼‰å››ç»´tensorå€¼éƒ½æ˜¯0

            n = b.shape[0]  # number of targets  # ä¸€ä¸ªbatch16å¼ å›¾ç‰‡çš„txtç»è¿‡æ‰©å……æ•°æ®é›†åœ¨ç¬¬ä¸€ä¸ªyoloæ£€æµ‹å¤´å±‚ä¸Šæ‹¥æœ‰çš„GTä¸ªæ•°  debugçš„æ—¶å€™ä¸º n=462
            if n:
                # pxy, pwh, _, pcls = pi[b, a, gj, gi].tensor_split((2, 4, 5), dim=1)  # faster, requires torch 1.8.0
                pxy, pwh, _, pcls = pi[b, a, gj, gi].split((2, 2, 1, self.nc), 1)  # target-subset of predictions  ä»é¢„æµ‹ç»“æœä¸­åˆ†åˆ©ç”¨æ©è†œä»16*3*80*80ä¸­æå–å‡º462ä¸ªæœ‰å¯¹åº”GTçš„pred_bboxç»“æœ

                # Regression  boxå›å½’è¯¯å·®
                pxy = pxy.sigmoid() * 2 - 0.5  # anchoråˆ°pred_bboxéœ€è¦çš„   ç§»åŠ¨å› å­
                pwh = (pwh.sigmoid() * 2) ** 2 * anchors[i]  # anchoråˆ°pred_bboxéœ€è¦çš„  å®½é«˜ç¼©æ”¾å› å­
                pbox = torch.cat((pxy, pwh), 1)  # predicted box
                iou = bbox_iou(pbox, tbox[i], CIoU=True).squeeze()  # iou(prediction, target)   # -------- è®¡ç®—é¢„æµ‹pred_bboxå’ŒGTé—´çš„CIOU  iouæ˜¯462çš„tensorå‘é‡
                lbox += (1.0 - iou).mean()  # iou loss  # ------------------------é€šè¿‡CIOUè®¡ç®—  æ¨¡å‹é¢„æµ‹ç»“æœå’ŒGTçš„ boxå›å½’è¯¯å·®loss

                # Objectness
                iou = iou.detach().clamp(0).type(tobj.dtype)
                if self.sort_obj_iou:  # è¿›ä¸å»
                    j = iou.argsort()
                    b, a, gj, gi, iou = b[j], a[j], gj[j], gi[j], iou[j]
                if self.gr < 1:  # è¿›ä¸å»
                    iou = (1.0 - self.gr) + self.gr * iou
                tobj[b, a, gj, gi] = iou  # iou ratio  # tobjåœ¨ä¸Šé¢åˆå§‹åŒ–ä¸º(16ï¼Œ3ï¼Œ80ï¼Œ80)æ˜¯0  ç°åœ¨èµ‹å€¼ä¸º pred_bboxå’ŒGTçš„iou

                # Classification   åæ­£è¿™ä¸€æ®µå°±æ˜¯æ±‚äº† ä¸€ä¸‹åˆ†ç±»æŸå¤±  ç”¨çš„äºŒè‡³äº¤å‰ç†µBCEloss
                if self.nc > 1:  # cls loss (only if multiple classes)    nc=2
                    t = torch.full_like(pcls, self.cn, device=self.device)  # targets  pclsæ˜¯é¢„æµ‹æ¯ä¸ªç±»åˆ«çš„å¾—åˆ†(462,2) self.cn=0è¡¨ç¤ºæ–°å»ºçš„téƒ½å¡«å……ä¸º0ï¼Œ
                    t[range(n), tcls[i]] = self.cp
                    lcls += self.BCEcls(pcls, t)  # BCE

                # Append targets to text file
                # with open('targets.txt', 'a') as file:
                #     [file.write('%11.5g ' * 4 % tuple(x) + '\n') for x in torch.cat((txy[i], twh[i]), 1)]

            obji = self.BCEobj(pi[..., 4], tobj)  # ç‰©ä½“ç½®ä¿¡åº¦æŸå¤±ä¹Ÿç”¨BCEloss
            lobj += obji * self.balance[i]  # obj loss
            if self.autobalance:  # è¿›ä¸å»  ---- å›åˆ°å¾ªç¯è®¡ç®—ä¸‹ä¸€ä¸ª yoloæ£€æµ‹å¤´çš„boxã€objã€clsæŸå¤±  å¾ªç¯3æ¬¡
                self.balance[i] = self.balance[i] * 0.9999 + 0.0001 / obji.detach().item()

        if self.autobalance:  # è¿›å…¥å»
            self.balance = [x / self.balance[self.ssi] for x in self.balance]
        lbox *= self.hyp['box']  # ä¸‰ä¸ªyoloå±‚æ±‡æ€»å¾—åˆ°çš„è¿™ä¸ªæŸå¤± Ã— è¶…å‚æ•°ä¸­çš„æŸå¤±æƒé‡ç³»æ•°
        lobj *= self.hyp['obj']
        lcls *= self.hyp['cls']
        bs = tobj.shape[0]  # batch size = 16

        return (lbox + lobj + lcls) * bs, torch.cat((lbox, lobj, lcls)).detach()

    def build_targets(self, p, targets):
        # Build targets for compute_loss(), input targets(image,class,x,y,w,h)
        na, nt = self.na, targets.shape[0]  # number of anchors, targets  # na=3ï¼Œ nt=137
        tcls, tbox, indices, anch = [], [], [], []
        gain = torch.ones(7, device=self.device)  # normalized to gridspace gain    gain=[1,1,1, 1,1,1,1]  7ä¸ª1æ˜¯tensoræ•°ç»„
        ai = torch.arange(na, device=self.device).float().view(na, 1).repeat(1, nt)  # same as .repeat_interleave(nt)  # aiæ˜¯3è¡Œ 137åˆ—äºŒç»´tensor ç¬¬ä¸€è¡Œæ˜¯137ä¸ª0ï¼Œç¬¬äºŒè¡Œå…¨ä¸º1ï¼Œç¬¬ä¸‰è¡Œå…¨ä¸º2    repeatå‡½æ•°è¡¨ç¤ºç¬¬0ç»´åº¦å¤åˆ¶1æ¬¡ï¼ˆæ²¡å˜ï¼‰ï¼Œç¬¬1ç»´åº¦å¤åˆ¶137æ¬¡
        targets = torch.cat((targets.repeat(na, 1, 1), ai[..., None]), 2)  # append anchor indices  targetsä»(137,5)å…ˆå˜æˆ(3,137,6) å†å’Œ (3,137,1)çš„æ–°aiå˜é‡åœ¨ç¬¬2ç»´åº¦æ‹¼æ¥ æ‹¼æ¥åtargetsæ˜¯(3,137,7)ä¹Ÿå°±æ˜¯æ¯”åŸæ¥å¤šäº†ä¸€åˆ—0   repeatè¿™é‡Œå…ˆåœ¨ç¬¬0ç»´åº¦å¤åˆ¶3æ¬¡ï¼ˆå¢åŠ ä¸€ä¸ªç»´åº¦ï¼‰
        g = 0.5  # bias
        off = torch.tensor(
            [
                [0, 0],
                [1, 0],
                [0, 1],
                [-1, 0],
                [0, -1],  # j,k,l,m
                # [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm
            ],
            device=self.device).float() * g  # offsets

        for i in range(self.nl):
            anchors, shape = self.anchors[i], p[i].shape  # anchorsæ˜¯(3,2)  shapeæ˜¯predçš„ç»“æœå½¢çŠ¶(16,3,80,80,7)   anchors æ˜¯é…ç½®æ–‡ä»¶9ä¸ªanchoråˆ†3ç»„å„è‡ªä¸‹é‡‡æ ·8ã€16ã€32å€åçš„9ä¸ªanchor å–self.anchors[0]å°±æ˜¯ä¸‹é‡‡æ ·8çš„ç¬¬ä¸€ä¸ªyoloå±‚çš„3ä¸ªanchorï¼Œå…¶ç‰¹å¾å›¾å°ºå¯¸80*80
            gain[2:6] = torch.tensor(shape)[[3, 2, 3, 2]]  # xyxy gain å°†ä¸Šè¡Œshapeä¸­ç¬¬4ï¼Œ3ï¼Œ4ï¼Œ3ä¸ªæ•°æ® èµ‹å€¼ç»™gainçš„ä»ç¬¬3åˆ°ç¬¬6ä¸ªä½ç½®çš„æ•° æ‰§è¡Œå®Œå gain=[1,1,80,80,80,80,1]åªæœ‰7ä¸ªå…ƒç´ çš„ä¸€ç»´tensor

            # Match targets to anchors
            t = targets * gain  # shape(3,n,7)   # å°†æ ‡æ³¨txtä¸­çš„0-1xywhä¿¡æ¯æ˜ å°„ä¸ºç‰¹å¾å›¾å¤§å°çš„GT_featuremap   ------ å»å½’ä¸€åŒ–
            if nt:
                # Matches
                r = t[..., 4:6] / anchors[:, None]  # wh ratio   ræ˜¯ï¼ˆ3ï¼Œ137ï¼Œ2ï¼‰  3å¼ 137è¡Œ2åˆ—çš„è¡¨ï¼šç¬¬ä¸€å¼ è¡¨æ˜¯targerç¬¬ä¸€å±‚å’Œç¬¬ä¸€ä¸ªyoloå±‚ä¸­3ä¸ªä¸­ç¬¬ä¸€ä¸ªanchorçš„æ¯”å€¼è¡¨ï¼Œç¬¬äºŒã€ä¸‰å±‚ç±»æ¨ã€(137,2)ä¸­ç¬¬ä¸€åˆ—æ˜¯GT_feature:å‰3ä¸ªanchoræ˜ å°„åˆ°ç¬¬ä¸€å±‚yoloå±‚çš„wä¹‹æ¯”   ç¬¬äºŒåˆ—æ˜¯hä¹‹æ¯”ã€‘
                j = torch.max(r, 1 / r).max(2)[0] < self.hyp['anchor_t']  # jæ˜¯(3,137)äºŒç»´å­˜æ”¾Trueã€Falseçš„è¡¨  3è¡Œè¡¨ç¤º3ä¸ªanchorï¼›æ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªGT_feature  å¦‚æœè¡¨çš„æŸè¡ŒæŸåˆ—æ˜¯Trueè¯´æ˜è¯¥GTå’Œæ”¹è¡Œçš„anchorå®½ä¹‹æ¯”ï¼œ4ï¼Œé«˜ä¹‹æ¯”ä¹Ÿï¼œ4
                # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))
                t = t[j]  # filter  tè¿™ä¸ªtargetå˜é‡ä» (3,137,7) ç»è¿‡æœ¬è¡Œå˜ä¸º ï¼ˆ230ï¼Œ7ï¼‰äºŒç»´æ•°ç»„äº†ï¼ï¼ï¼ï¼  ----------------tä»(137,6)å˜ä¸º(230,7)æ˜¯æŠŠæœ‰çš„GTåŒ¹é…2ä¸ªæˆ–3ä¸ªanchorï¼Œè¯¥GTæ•°æ®ä»1è¡Œå˜ä¸º2è¡Œæˆ–3è¡Œï¼Œè¿™2ä¸¤æ•°æ®å”¯ä¸€çš„åŒºåˆ«åœ¨äºæœ€åä¸€åˆ—æ˜¯0å’Œ1æˆ–2

                # Offsets
                gxy = t[:, 2:4]  # grid xy  # gxyæ˜¯GTåœ¨ç‰¹å¾å›¾(å¦‚80*80)ä¸Šä¸­å¿ƒç‚¹çš„åæ ‡   å¦‚gxyä¸ºï¼ˆ46.7, 61.1ï¼‰è¿™ä¸ªç‚¹ï¼Œä¸è¿‡å®é™…ä¸Šgxyä¸æ­¢ä¸€ä¸ªç‚¹ï¼Œè€Œæ˜¯230ä¸ªç‚¹çš„xå’Œy
                gxi = gain[[2, 3]] - gxy  # inverse   # gxi è¿™ä¸ªå˜é‡åå­—ä½œè€…å–å¾—ä¸å¥½ï¼Œå®é™…ä¸Šå°±æ˜¯  ç‰¹å¾å›¾sizeå‡å»ä¸Šé¢çš„GTä¸­å¿ƒç‚¹åæ ‡ å¾—åˆ°çš„å°±æ˜¯ä¸­å¿ƒç‚¹åˆ°ç‰¹å¾å›¾å³è¾¹ã€ä¸‹è¾¹çš„è·ç¦» ï¼
                j, k = ((gxy % 1 < g) & (gxy > 1)).T  # jå’Œkéƒ½æ˜¯230ä¸ªå…ƒç´ çš„Trueã€Falseå‘é‡ï¼›jè¡¨ç¤ºGTçš„ä¸­å¿ƒç‚¹æ˜¯å¦ä½äºè‡ªèº«æ‰€åœ¨grid_cellçš„å·¦åŠä¾§ï¼ˆx<0.5ï¼‰ï¼Œkè¡¨ç¤ºGTçš„ä¸­å¿ƒç‚¹æ˜¯å¦ä½äºè‡ªèº«grid_cellçš„ä¸ŠåŠä¾§(y<0.5)
                l, m = ((gxi % 1 < g) & (gxi > 1)).T  # åŒç†ï¼Œlåˆ¤æ–­GTçš„ä¸­å¿ƒç‚¹æ˜¯å¦ä½äºå³åŠä¾§ï¼ˆx>0.5ï¼‰; måˆ¤æ–­æ˜¯å¦ä½äºä¸‹åŠä¾§ï¼ˆy>0.5ï¼‰   --- gxy>1å’Œgxi>1 æ˜¯å»é™¤80*80ç‰¹å¾å›¾çš„è¾¹ç¼˜ä¸€åœˆåƒç´ 
                j = torch.stack((torch.ones_like(j), j, k, l, m))  # jå°†5ä¸ªã€230ä¸ªå…ƒç´ çš„å‘é‡ã€‘æ‹¼æˆ  (5ï¼Œ230) äºŒç»´tensor  ç¬¬ä¸€è¡Œå…¨ä¸ºTrueï¼Œç¬¬äºŒè¡Œæ˜¯åŸæ¥jçš„å€¼ï¼Œç¬¬ä¸‰è¡Œæ˜¯kï¼Œç„¶åæ˜¯l,m
                t = t.repeat((5, 1, 1))[j]  # tå…ˆä»(230,7)å˜ä¸º(5,230,7)  ç»è¿‡[j]åå˜ä¸º(690,7)  å®é™…ä¸Šå°±æ˜¯æ¯ä¸ªGTå¢åŠ äº†å‘¨å›´2ä¸ªæ–°GTï¼Œæ‰€ä»¥tä»230ä¸ªå¢å¤§3å€åˆ°690ä¸ªäº†ã€‚å¢åŠ çš„æ–°GTå¯ä»¥æ˜¯åŸGTå·¦ä¸Šã€å³ä¸Šã€å·¦ä¸‹ã€å³ä¸‹ä»»æ„ä¸€ç»„çš„ä¸¤ä¸ªæ–°grid_cell
                offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]
            else:
                t = targets[0]
                offsets = 0

            # Define
            bc, gxy, gwh, a = t.chunk(4, 1)  # (image, class), grid xy, grid wh, anchors  # bcè¡¨ç¤ºä»ç¬¬1åˆ°ç¬¬690ä¸ªGTå„è‡ªæ‰€å±çš„batchå’Œclassæ˜¯ä»€ä¹ˆ(690,2)  gxyã€gwhåŒç†éƒ½æ˜¯(690,2) aåˆ™æ˜¯(690,1)
            a, (b, c) = a.long().view(-1), bc.long().T  # anchors, image, class   # å°†aå˜ä¸ºï¼ˆ690ï¼‰çš„å‘é‡ ï¼Œbå’Œcä»ï¼ˆbï¼Œcï¼‰ä¸­æå–ä¸ºä¸€ç»´ å‘é‡ éƒ½æ˜¯(690)
            gij = (gxy - offsets).long()  # gij å°±æ˜¯GTä¸­å¿ƒç‚¹çš„å‘ä¸‹å–æ•´   ä¹Ÿå°±æ˜¯æ‰€åœ¨grid_cellå·¦ä¸Šè§’åæ ‡ ã€å®é™…ä¸Šæ˜¯åŒ…æ‹¬ä¸¤æ¬¡æ‰©å……æ­£æ ·æœ¬ä¹‹åçš„ç‚¹æœ‰690ä¸ªã€‘
            gi, gj = gij.T  # grid indices  # ä»gijäºŒç»´tensorä¸­  å•ç‹¬æå– gi å’Œ gj éƒ½æ˜¯ï¼ˆ690ï¼‰çš„ä¸€ç»´tensor

            # Append
            indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1)))  # image, anchor, grid  # indicesæ˜¯ä¸€ä¸ªlisté‡Œé¢åªæœ‰ä¸€ä¸ªtupleå…ƒç´ ï¼Œtupleä¸­æœ‰å››ä¸ªtensorå‘é‡å…ƒç´  4ä¸ªtensoråˆ†åˆ«æ˜¯æ‰€å±batchã€andhorã€æ‰€åœ¨ç‰¹å¾å›¾çš„è¡Œæ•°gjã€åˆ—æ•°gi
            tbox.append(torch.cat((gxy - gij, gwh), 1))  # box  tboxæ˜¯listé‡Œé¢æœ‰ä¸€ä¸ªtensorå…ƒç´  è¿™ä¸ªtensoræ˜¯(690,4)690è¡¨ç¤ºæ‰©å……åæœ‰690ä¸ªGTæ¯è¡Œæ˜¯ Î”xï¼ŒÎ”yï¼Œwï¼Œhå››ä¸ªæ•°ã€‚éœ€æ³¨æ„Î”xå’ŒÎ”yçš„å–å€¼èŒƒå›´æ˜¯ï¼ˆ-0.5åˆ°1.5ï¼‰! 690ä¸ªGTé¡ºåºï¼šå‰ä¸‰åˆ†ä¹‹ä¸€çš„GTï¼ˆ230ä¸ªï¼‰éƒ½æ˜¯æœ¬gridcellçš„GTï¼Œåé¢å‰©ä¸‹çš„ä¸‰åˆ†ä¹‹äºŒçš„GTéšæœºåˆ†å¸ƒåœ¨åŸgrid_cellçš„å·¦ã€ä¸Šã€å³ã€ä¸‹4ä¸ªgrid_cellä¸­çš„1ä¸ªï¼Œä¸”é¡ºåºå°±æ˜¯å…ˆæŠŠå·¦è¾¹çš„éƒ½æ”¾ä¸€å †ï¼Œç„¶åæ˜¯ä¸Šé¢çš„ä»¥æ­¤ç±»æ¨
            anch.append(anchors[a])  # anchors  æŠŠ690ä¸ªGTåŒ¹é…çš„anchoræ”¾å…¥  anch  å…¶ä¸­anchæ˜¯ä¸ªlistï¼Œé‡Œé¢æœ‰ä¸€ä¸ªtensorå…ƒç´   è¿™ä¸ªtensoræ˜¯ï¼ˆ690ï¼Œ2ï¼‰çš„äºŒç»´å¼ é‡ï¼Œ 2åˆ—åˆ†åˆ«æ˜¯anchorçš„å®½é«˜ã€å½“ç„¶anchoræ˜¯æ˜ å°„åˆ°ç‰¹å¾å›¾åå¤§å°çš„anchorã€‘
            tcls.append(c)  # class

        return tcls, tbox, indices, anch
        # tcls, tbox, indices, anch  å››ä¸ªè¿”å›å€¼éƒ½æ˜¯list ä¸”listä¸­éƒ½åªæœ‰3ä¸ªå…ƒç´ ï¼Œåˆ†åˆ«è®°å½•æ¯ä¸ªæ£€æµ‹å¤´çš„ç›¸å…³ä¿¡æ¯
        # tclsæ˜¯æœ‰3ä¸ªå…ƒç´ çš„listï¼Œç¬¬1ä¸ªå…ƒç´ æ˜¯txtæ–‡ä»¶ä¸­GTåŒ¹é…ç¬¬ä¸€å±‚çš„3ä¸ªanchoræ‰©å……GTåçš„690ä¸ªå…ƒç´ çš„tensorï¼Œç¬¬2ä¸ªå…ƒç´ æ˜¯åŒ¹é…ç¬¬äºŒå±‚yoloå±‚çš„835ä¸ªå…ƒç´ çš„tensorï¼Œç¬¬ä¸‰ä¸ªå…ƒç´ æ˜¯åŒ¹é…ç¬¬ä¸‰ä¸ªæ£€æµ‹å¤´çš„anchorçš„420ä¸ªå…ƒç´ çš„tensor
        # tboxåŒç†ä¹Ÿæ˜¯[]listä¸­æœ‰3ä¸ªtensorå…ƒç´ ï¼Œæ¯ä¸ªå…ƒç´ åˆ†åˆ«æ˜¯å¯¹åº”3ä¸ªyoloæ£€æµ‹å¤´ï¼Œå…·ä½“è€Œè¨€æ¯ä¸ªtensorä¸­å­˜æ”¾çš„æ˜¯ Î”xï¼ŒÎ”yï¼Œwï¼Œh å…¶ä¸­Î”xï¼ŒÎ”yéƒ½æ˜¯-0.5åˆ°1.5çš„å–å€¼èŒƒå›´ï¼Œwhéƒ½æ˜¯GTæ˜ å°„åˆ°ç‰¹å¾å›¾ä¸Šåçš„å¤§å°